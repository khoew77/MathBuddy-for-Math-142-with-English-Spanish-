# -*- coding: utf-8 -*-
import pymysql
import streamlit as st
from openai import OpenAI
import os
import json
from datetime import datetime
import fitz  # PyMuPDF
from PIL import Image
import pytesseract
import matplotlib.pyplot as plt
import numpy as np
import re

# --- 1. TRANSLATIONS DICTIONARY ---
translations = {
    "en": {
        "page_title": "MathBuddy",
        "welcome_title": "üìö Welcome to MathBuddy",
        "welcome_image_caption": "Your Study Companion for Math Success üì±",
        "welcome_prompt": "Please enter your student ID and name to get started.",
        "student_id_label": "üÜî Student ID",
        "name_label": "üë§ Name",
        "next_button": "‚ñ∂Ô∏è Next",
        "error_missing_info": "‚ö†Ô∏è Oops! Please enter both your student ID and name.",
        "instructions_title": "üìñ How to Use MathBuddy",
        "instructions_body": """
           **1. Start a Conversation:** Explain your math question, problem, or goal.
           **2. Get Guided Feedback:** MathBuddy will ask questions and suggest improvements.
           **3. Ask Anything:** Don't hesitate to ask for clarification.
           **4. Move On When Ready:** When you're done, just click the **Next** button.
        """,
        "previous_button": "‚óÄÔ∏è Previous",
        "chat_title": "üí¨ Start Chatting with MathBuddy",
        "chat_prompt": "Describe your math question or upload a document to begin!",
        "tab_direct_chat": "‚úçÔ∏è Direct Chat",
        "tab_document_chat": "üìÑ Chat with a Document",
        "header_type_question": "Type your question here",
        "chat_placeholder": "Ask MathBuddy a question and press Enter...",
        "header_upload_file": "Upload a file to discuss",
        "file_uploader_label": "üìÅ Choose a PDF or image file",
        "file_process_spinner": "Processing file...",
        "file_process_success": "‚úÖ Successfully processed **{file_name}**.",
        "doc_chat_placeholder": "Ask a question about your document...",
        "subheader_recent_exchange": "üìå Most Recent Exchange",
        "info_first_exchange": "Your first exchange will appear here.",
        "subheader_full_history": "üìú Full Chat History",
        "graph_error": "‚ö†Ô∏è An error occurred while generating the graph:\n{e}",
        "wrap_up_title": "üéâ Wrap-Up: Final Reflection",
        "spinner_generating_feedback": "Generating your feedback summary...",
        "subheader_feedback_summary": "üìã Feedback Summary",
        "feedback_not_generated": "No summary generated yet.",
        "save_failed": "‚ùå Failed to save conversation. Please try again!",
        "initial_prompt": (
            "You are a helpful, supportive chatbot named MathBuddy. Your job is to guide college-level math students without solving problems for them. "
            "Your tone is friendly, clear, and educational. Do not use LaTeX or special symbols. Explain math in plain English. "
            "If the user asks for a graph of a specific function (e.g., 'graph y=x^2'), your response MUST start immediately with the Python code block and contain NOTHING ELSE. "
            "The code must be enclosed in a single Python code block (```python...). "
            "Your code will be executed in an environment where `fig, ax = plt.subplots()` has ALREADY been run. "
            "Therefore, you MUST NOT include `import matplotlib.pyplot as plt` or `fig, ax = plt.subplots()` in your code. "
            "You MUST use the pre-existing `ax` variable to plot (e.g., `ax.plot(...)`, `ax.set_title(...)`, `ax.grid(True)`). "
            "Do NOT provide code for a different function than the one requested. Do not include `plt.show()`."
        )
    },
    "es": {
        "page_title": "MathBuddy",
        "welcome_title": "üìö Bienvenido a MathBuddy",
        "welcome_image_caption": "Tu Compa√±ero de Estudio para el √âxito en Matem√°ticas üì±",
        "welcome_prompt": "Por favor, ingresa tu n√∫mero de estudiante y tu nombre para comenzar.",
        "student_id_label": "üÜî N√∫mero de Estudiante",
        "name_label": "üë§ Nombre",
        "next_button": "‚ñ∂Ô∏è Siguiente",
        "error_missing_info": "‚ö†Ô∏è ¬°Uy! Por favor, ingresa tanto tu n√∫mero de estudiante como tu nombre.",
        "instructions_title": "üìñ C√≥mo Usar MathBuddy",
        "instructions_body": """
           **1. Inicia una Conversaci√≥n:** Explica tu pregunta de matem√°ticas, problema u objetivo.
           **2. Recibe Orientaci√≥n:** MathBuddy te har√° preguntas y sugerir√° mejoras.
           **3. Pregunta lo que Quieras:** No dudes en pedir aclaraciones.
           **4. Avanza Cuando Est√©s Listo:** Cuando termines, simplemente haz clic en el bot√≥n **Siguiente**.
        """,
        "previous_button": "‚óÄÔ∏è Anterior",
        "chat_title": "üí¨ Comienza a Chatear con MathBuddy",
        "chat_prompt": "¬°Describe tu pregunta de matem√°ticas o sube un documento para empezar!",
        "tab_direct_chat": "‚úçÔ∏è Chat Directo",
        "tab_document_chat": "üìÑ Chatear con un Documento",
        "header_type_question": "Escribe tu pregunta aqu√≠",
        "chat_placeholder": "Haz una pregunta a MathBuddy y presiona Enter...",
        "header_upload_file": "Sube un archivo para discutir",
        "file_uploader_label": "üìÅ Elige un archivo PDF o de imagen",
        "file_process_spinner": "Procesando archivo...",
        "file_process_success": "‚úÖ Se proces√≥ exitosamente **{file_name}**.",
        "doc_chat_placeholder": "Haz una pregunta sobre tu documento...",
        "subheader_recent_exchange": "üìå Intercambio M√°s Reciente",
        "info_first_exchange": "Tu primer intercambio aparecer√° aqu√≠.",
        "subheader_full_history": "üìú Historial de Chat Completo",
        "graph_error": "‚ö†Ô∏è Ocurri√≥ un error al generar el gr√°fico:\n{e}",
        "wrap_up_title": "üéâ Conclusi√≥n: Reflexi√≥n Final",
        "spinner_generating_feedback": "Generando tu resumen de retroalimentaci√≥n...",
        "subheader_feedback_summary": "üìã Resumen de Retroalimentaci√≥n",
        "feedback_not_generated": "A√∫n no se ha generado un resumen.",
        "save_failed": "‚ùå No se pudo guardar la conversaci√≥n. ¬°Int√©ntalo de nuevo!",
        "initial_prompt": (
            "Eres un chatbot servicial y de apoyo llamado MathBuddy. Tu trabajo es guiar a estudiantes universitarios de matem√°ticas sin resolver los problemas por ellos. "
            "Tu tono es amigable, claro y educativo. No uses LaTeX ni s√≠mbolos especiales. Explica las matem√°ticas en espa√±ol sencillo. "
            "Si el usuario pide un gr√°fico de una funci√≥n espec√≠fica (por ejemplo, 'grafica y=x^2'), tu respuesta DEBE comenzar inmediatamente con el bloque de c√≥digo de Python y no contener NADA M√ÅS. "
            "El c√≥digo debe estar dentro de un √∫nico bloque de c√≥digo de Python (```python...). "
            "Tu c√≥digo se ejecutar√° en un entorno donde `fig, ax = plt.subplots()` YA ha sido ejecutado. "
            "Por lo tanto, NO DEBES incluir `import matplotlib.pyplot as plt` ni `fig, ax = plt.subplots()` en tu c√≥digo. "
            "DEBES usar la variable preexistente `ax` para graficar (por ejemplo, `ax.plot(...)`, `ax.set_title(...)`, `ax.grid(True)`). "
            "NO proporciones c√≥digo para una funci√≥n diferente a la solicitada. No incluyas `plt.show()`."
        )
    }
}

# --- GLOBAL CONFIGURATION AND SETUP ---
st.set_page_config(page_title="MathBuddy", page_icon="üßÆ", layout="centered")

# --- LANGUAGE SELECTOR IN SIDEBAR ---
st.sidebar.title("Language / Idioma")
language_options = ('English', 'Espa√±ol')
selected_language = st.sidebar.radio("lang_select", options=language_options, label_visibility="collapsed")

lang_code = 'es' if selected_language == 'Espa√±ol' else 'en'
if 'language' not in st.session_state or st.session_state.language != lang_code:
    st.session_state.language = lang_code
    st.rerun()

# --- HELPER FUNCTIONS ---
def t(key):
    return translations.get(st.session_state.language, {}).get(key, f"<{key}>")

OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
MODEL = 'gpt-4o'
client = OpenAI(api_key=OPENAI_API_KEY)

def extract_text_from_file(file):
    try:
        if file.type == "application/pdf":
            doc = fitz.open(stream=file.read(), filetype="pdf")
            return "".join(page.get_text() for page in doc)
        elif file.type.startswith("image/"):
            return pytesseract.image_to_string(Image.open(file))
    except Exception as e:
        st.error(f"‚ùå Error processing file: {e}")
        return None

def save_to_db(all_data):
    number = st.session_state.get('user_number', '').strip()
    name = st.session_state.get('user_name', '').strip()
    if not number or not name:
        st.error(t("error_missing_info"))
        return False
    try:
        db = pymysql.connect(host=st.secrets["DB_HOST"], user=st.secrets["DB_USER"], password=st.secrets["DB_PASSWORD"], database=st.secrets["DB_DATABASE"], charset="utf8mb4", autocommit=True)
        cursor = db.cursor()
        chat = json.dumps(all_data, ensure_ascii=False)
        sql = "INSERT INTO qna (number, name, chat, time) VALUES (%s, %s, %s, %s)"
        cursor.execute(sql, (number, name, chat, datetime.now()))
        cursor.close()
        db.close()
        return True
    except Exception as e:
        st.error(f"‚ùå An error occurred: {e}")
        return False

def get_chatgpt_response(prompt, context=""):
    system_prompt = t('initial_prompt')
    system_messages = [{"role": "system", "content": system_prompt}]
    if context:
        context_prompt_text = "Use the following content from an uploaded document to answer the user's questions.\n\nDOCUMENT CONTENT:\n"
        if st.session_state.language == 'es':
            context_prompt_text = "Usa el siguiente contenido de un documento subido para responder las preguntas del usuario.\n\nCONTENIDO DEL DOCUMENTO:\n"
        system_messages.append({"role": "system", "content": context_prompt_text + context[:4000]})
    
    messages_to_send = system_messages + st.session_state.get("messages", []) + [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(model=MODEL, messages=messages_to_send)
    answer = response.choices[0].message.content
    st.session_state.messages.append({"role": "user", "content": prompt})
    st.session_state.messages.append({"role": "assistant", "content": answer})
    st.session_state.recent_message = {"user": prompt, "assistant": answer}

def handle_direct_chat():
    prompt = st.session_state.direct_chat_box
    if prompt and prompt.strip():
        get_chatgpt_response(prompt)
        st.session_state.direct_chat_box = ""

def render_message_content(content):
    match = re.search(r"```(python)?\n?(.*)```", content, re.DOTALL)
    if match and ('ax.plot' in content or 'ax.scatter' in content):
        code = match.group(2).strip()
        try:
            fig, ax = plt.subplots()
            exec(code, {'plt': plt, 'np': np, 'ax': ax, 'fig': fig})
            st.pyplot(fig)
            plt.close(fig)
        except Exception as e:
            st.error(t("graph_error").format(e=e))
            st.code(code, language='python')
    else:
        st.markdown(content)

# --- PAGE DEFINITIONS ---

def page_1():
    st.title(t("welcome_title"))
    st.image("mathbuddy_promo.png", caption=t("welcome_image_caption"), width=300)
    st.write(t("welcome_prompt"))
    st.session_state.user_number = st.text_input(t("student_id_label"), value=st.session_state.get("user_number", ""))
    st.session_state.user_name = st.text_input(t("name_label"), value=st.session_state.get("user_name", ""))
    if st.button(t("next_button"), key="page1_next"):
        if not st.session_state.user_number.strip() or not st.session_state.user_name.strip():
            st.error(t("error_missing_info"))
        else:
            st.session_state.step = 2
            st.rerun()

def page_2():
    st.title(t("instructions_title"))
    st.info(t("instructions_body"))
    col1, col2 = st.columns(2)
    with col1:
        if st.button(t("previous_button")):
            st.session_state.step = 1
            st.rerun()
    with col2:
        if st.button(t("next_button"), key="page2_next"):
            st.session_state.step = 3
            st.rerun()

def page_3():
    st.title(t("chat_title"))
    st.write(t("chat_prompt"))
    tab1, tab2 = st.tabs([t("tab_direct_chat"), t("tab_document_chat")])

    with tab1:
        st.header(t("header_type_question"))
        st.text_input("...", key="direct_chat_box", on_change=handle_direct_chat, placeholder=t("chat_placeholder"), label_visibility="collapsed")

    with tab2:
        st.header(t("header_upload_file"))
        uploaded_file = st.file_uploader(t("file_uploader_label"), type=["pdf", "png", "jpg", "jpeg"])
        if uploaded_file and st.session_state.get("processed_file_name") != uploaded_file.name:
            with st.spinner(t("file_process_spinner")):
                st.session_state.file_text = extract_text_from_file(uploaded_file)
                st.session_state.processed_file_name = uploaded_file.name
        if st.session_state.get("file_text"):
            st.success(t("file_process_success").format(file_name=st.session_state.processed_file_name))
            if prompt := st.chat_input(t("doc_chat_placeholder")):
                get_chatgpt_response(prompt, context=st.session_state.file_text)
                st.rerun()

    st.divider()
    st.subheader(t("subheader_recent_exchange"))
    recent = st.session_state.get("recent_message", {"user": "", "assistant": ""})
    if recent["user"] or recent["assistant"]:
        with st.chat_message("user"):
            st.markdown(recent["user"])
        with st.chat_message("assistant"):
            render_message_content(recent["assistant"])
    else:
        st.info(t("info_first_exchange"))
    
    st.divider()
    st.subheader(t("subheader_full_history"))
    if st.session_state.messages:
        for msg in reversed(st.session_state.messages):
            with st.chat_message(msg["role"]):
                render_message_content(msg["content"])

    st.divider()
    col1, col2 = st.columns(2)
    with col1:
        if st.button(t("previous_button")):
            st.session_state.step = 2
            st.rerun()
    with col2:
        if st.button(t("next_button"), key="page3_next"):
            st.session_state.step = 4
            st.session_state.feedback_saved = False
            st.rerun()

def page_4():
    st.title(t("wrap_up_title"))
    if not st.session_state.get("feedback_saved"):
        with st.spinner(t("spinner_generating_feedback")):
            chat_history = "\n".join(f"{msg['role']}: {msg['content']}" for msg in st.session_state.messages)
            prompt_summary_en = f"This is a conversation between a student and MathBuddy:\n{chat_history}\n\nPlease summarize the key concepts discussed, note the student's areas of strength, and suggest improvements or study tips for them to continue their learning."
            prompt_summary_es = f"Esta es una conversaci√≥n entre un estudiante y MathBuddy:\n{chat_history}\n\nPor favor, resume los conceptos clave discutidos, se√±ala las fortalezas del estudiante y sugiere mejoras o consejos de estudio para que contin√∫en aprendiendo."
            prompt = prompt_summary_es if st.session_state.language == 'es' else prompt_summary_en
            response = client.chat.completions.create(model=MODEL, messages=[{"role": "system", "content
